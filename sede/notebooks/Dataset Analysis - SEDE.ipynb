{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "import srsly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_json = json.load(open('../stackexchange_schema/tables_so.json'))\n",
    "train_sede = [line for line in srsly.read_jsonl('../data/sede/train.jsonl')]\n",
    "dev_sede = [line for line in srsly.read_jsonl('../data/sede/val.jsonl')]\n",
    "test_sede = [line for line in srsly.read_jsonl('../data/sede/test.jsonl')]\n",
    "train_dev_test = train_sede + dev_sede + test_sede"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12023"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dev_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QuerySetId': 2803,\n",
       " 'Title': 'Users by location, with a minimum reputation',\n",
       " 'Description': None,\n",
       " 'QueryBody': 'WITH  a minimum reputation\\n\\nselect\\n  Id as \"User Link\",\\n  Reputation,\\n  WebsiteUrl as \"Website URL\",\\n  Location\\nfrom Users\\nwhere\\n  Location like \\'%##location##%\\' and\\n  Reputation >= ##minimumReputation##\\norder by Reputation desc',\n",
       " 'CreationDate': '2020-12-09 04:38:29',\n",
       " 'validated': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dev_test[30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of different queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11767"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = set([ex['QueryBody'].lower() for ex in train_dev_test])\n",
    "len(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of SQL n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173343\n"
     ]
    }
   ],
   "source": [
    "ngrams = set()\n",
    "n = 3\n",
    "for ex in train_dev_test:\n",
    "    tokens = [t.lower() for t in ex['QueryBody'].split()]\n",
    "    for i in range(len(tokens)-n+1):\n",
    "        ngrams.add(tuple(tokens[i:i+n]))\n",
    "print(len(ngrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of question n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42615\n"
     ]
    }
   ],
   "source": [
    "ngrams = set()\n",
    "n = 3\n",
    "for ex in train_dev_test:\n",
    "    tokens = [t.lower() for t in ex['Title'].split() if t not in ['.', '?', ',']]  # spider doesn't contain other punctuations AFAIR, but we should replace this with a better filter for other datasets\n",
    "    for i in range(len(tokens)-n+1):\n",
    "        ngrams.add(tuple(tokens[i:i+n]))\n",
    "print(len(ngrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average tables per question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemas = {}\n",
    "for db_json in tables_json:\n",
    "    db_id = db_json['db_id']\n",
    "    table_names = db_json[\"table_names_original\"]\n",
    "    columns = [(column_name[0], column_name[1]) for column_name in db_json[\"column_names_original\"]]\n",
    "    schemas[db_id] = {}\n",
    "    for table_index, table_name in enumerate(table_names):\n",
    "        schemas[db_id][table_name] = []\n",
    "        table_columns = [column for column in columns if column[0] == table_index]\n",
    "        for table_column in table_columns:\n",
    "            schemas[db_id][table_name].append(table_column[1])\n",
    "\n",
    "# print(schemas[\"farm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tables: 29\n",
      "Number of columns: 211\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of tables: {len(schemas['stackexchange'])}\")\n",
    "num_of_columns = sum([len(columns) for _, columns in schemas[\"stackexchange\"].items()])\n",
    "print(f\"Number of columns: {num_of_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1445562671546203\n"
     ]
    }
   ],
   "source": [
    "counts = []\n",
    "for ex in train_dev_test:\n",
    "    available_tables = set([t.lower() for t in schemas[ex.get('db_id', \"stackexchange\")].keys()])\n",
    "    table_tokens_used = [t for t in ex['QueryBody'].split() if t.lower() in available_tables]\n",
    "#     print(table_tokens_used)\n",
    "#     print(available_tables)\n",
    "#     print([t.lower() for t in ex['QueryBody'].split()])\n",
    "    counts.append(len(table_tokens_used))\n",
    "print(sum(counts) / len(counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anonymized queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664\n"
     ]
    }
   ],
   "source": [
    "templates = dict()\n",
    "for ex in train_dev_test:\n",
    "    query = ex['QueryBody'].replace('(', ' ( ').replace(')', ' ) ').lower().strip('; ')\n",
    "    query = re.sub(r'\".*\"', '{value}', query)\n",
    "    query = re.sub(r\"'.*'\", '{value}', query)\n",
    "    query = re.sub(r\"\\s\\d+.\\d+\", '{number}', query)\n",
    "    query = re.sub(r\"\\s\\d+\", '{number}', query)\n",
    "    query_tokens = [t for t in query.split() if t]\n",
    "    \n",
    "    for i, token in enumerate(query_tokens):\n",
    "        if token.startswith(\"t1.\") or token.startswith(\"t2.\") or token.startswith(\"t3.\"):\n",
    "            query_tokens[i] = \"{item}\"\n",
    "    \n",
    "    available_tables = set([t.lower() for t in schemas[ex.get('db_id', \"stackexchange\")].keys()])\n",
    "    available_columns = set([c.lower() for t in schemas[ex.get('db_id', \"stackexchange\")].values() for c in t])\n",
    "    \n",
    "    available_items = available_tables.union(available_columns)\n",
    "    \n",
    "    anonymized = \" \".join(['{item}' if t in available_items else t for t in query_tokens])\n",
    "    if anonymized not in templates:\n",
    "        templates[anonymized] = 1\n",
    "    else:\n",
    "        templates[anonymized] += 1\n",
    "#     print(query)\n",
    "#     print(available_items)\n",
    "#     print(' '.join(anonymized))\n",
    "#     print(\"****\")\n",
    "\n",
    "print(len(templates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. # queries / templates = 1.1274381095273818\n"
     ]
    }
   ],
   "source": [
    "print(f\"Avg. # queries / templates = {sum(list(templates.values()))/len(templates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
