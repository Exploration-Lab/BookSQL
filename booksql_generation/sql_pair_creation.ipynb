{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d210724f",
   "metadata": {},
   "source": [
    "OLD original file , dont use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ac9cbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06bc7964-822e-41cb-a262-f042fbbb5949",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb9dfa18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/rahul/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dc72b40-58d0-4eea-b411-699b8536bb48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>sql</th>\n",
       "      <th>Levels</th>\n",
       "      <th>Changes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How much did [customer_name] spend on [account...</td>\n",
       "      <td>select sum(debit) from master_txn_table  as T1...</td>\n",
       "      <td>hard</td>\n",
       "      <td>criteria : -\\n\\nEASY : simple queries with sin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did we get paid for the [product_name] in [dat...</td>\n",
       "      <td>select distinct transaction_id, AR_paid from m...</td>\n",
       "      <td>medium</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Have we billed [customer_name] for the [produc...</td>\n",
       "      <td>select distinct transaction_id from master_txn...</td>\n",
       "      <td>medium</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the average spend per month on [accoun...</td>\n",
       "      <td>select sum(debit)/12 from master_txn_table  as...</td>\n",
       "      <td>hard</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what was our top [number] selling products and...</td>\n",
       "      <td>select product_service, sum(quantity) from mas...</td>\n",
       "      <td>hard</td>\n",
       "      <td>add template here - done \\n[number] can take v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question   \n",
       "0  How much did [customer_name] spend on [account...  \\\n",
       "1  Did we get paid for the [product_name] in [dat...   \n",
       "2  Have we billed [customer_name] for the [produc...   \n",
       "3  What is the average spend per month on [accoun...   \n",
       "4  what was our top [number] selling products and...   \n",
       "\n",
       "                                                 sql  Levels   \n",
       "0  select sum(debit) from master_txn_table  as T1...    hard  \\\n",
       "1  select distinct transaction_id, AR_paid from m...  medium   \n",
       "2  select distinct transaction_id from master_txn...  medium   \n",
       "3  select sum(debit)/12 from master_txn_table  as...    hard   \n",
       "4  select product_service, sum(quantity) from mas...    hard   \n",
       "\n",
       "                                             Changes  \n",
       "0  criteria : -\\n\\nEASY : simple queries with sin...  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4  add template here - done \\n[number] can take v...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df1 = pd.read_csv(\"/data/unified_parser_text_to_sql/create_database_ours/data/dataset details.xlsx - sample questions.csv\")\n",
    "df1 = pd.read_csv(\"/DATA1/rahul/text2SQL/booksql_generation/generated_data/dataset details.xlsx - sample questions.csv\")\n",
    "\n",
    "df1= df1[:183]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6888d02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>sql</th>\n",
       "      <th>Levels</th>\n",
       "      <th>Changes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Show the invoice number and the number of item...</td>\n",
       "      <td>SELECT transaction_id ,  sum(quantity) FROM ma...</td>\n",
       "      <td>hard</td>\n",
       "      <td>Check this as well\\n[SH] updated query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Show the minimum, average, maximum order quant...</td>\n",
       "      <td>SELECT min(quantity_per_transaction) ,  avg(qu...</td>\n",
       "      <td>hard</td>\n",
       "      <td>Check this as well\\n[SH] updated query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>What are the names of products that have never...</td>\n",
       "      <td>SELECT product_service FROM Products_Service E...</td>\n",
       "      <td>medium</td>\n",
       "      <td>Check this as well\\n[SH] looks good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Show all product types and the total quantity ...</td>\n",
       "      <td>SELECT T2.product_service_type ,  sum(T1.quant...</td>\n",
       "      <td>hard</td>\n",
       "      <td>Check this as well\\n[SH] updated query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>How many products are never sold with total va...</td>\n",
       "      <td>SELECT count(*) FROM Product_Service WHERE pro...</td>\n",
       "      <td>hard</td>\n",
       "      <td>Check this as well\\n[SH] updated query</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question   \n",
       "178  Show the invoice number and the number of item...  \\\n",
       "179  Show the minimum, average, maximum order quant...   \n",
       "180  What are the names of products that have never...   \n",
       "181  Show all product types and the total quantity ...   \n",
       "182  How many products are never sold with total va...   \n",
       "\n",
       "                                                   sql  Levels   \n",
       "178  SELECT transaction_id ,  sum(quantity) FROM ma...    hard  \\\n",
       "179  SELECT min(quantity_per_transaction) ,  avg(qu...    hard   \n",
       "180  SELECT product_service FROM Products_Service E...  medium   \n",
       "181  SELECT T2.product_service_type ,  sum(T1.quant...    hard   \n",
       "182  SELECT count(*) FROM Product_Service WHERE pro...    hard   \n",
       "\n",
       "                                    Changes  \n",
       "178  Check this as well\\n[SH] updated query  \n",
       "179  Check this as well\\n[SH] updated query  \n",
       "180     Check this as well\\n[SH] looks good  \n",
       "181  Check this as well\\n[SH] updated query  \n",
       "182  Check this as well\\n[SH] updated query  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c176e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ade25d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Levels\n",
       "medium    100\n",
       "hard       80\n",
       "easy        3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Levels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83779f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 183 entries, 0 to 182\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   question  183 non-null    object\n",
      " 1   sql       183 non-null    object\n",
      " 2   Levels    183 non-null    object\n",
      " 3   Changes   37 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 5.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ab93999",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.rename(columns = {'question':'Query Pattern','sql':'Sql pattern'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54d159ca-bfa6-4b88-b84c-c0197db60f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  0\n",
      "Train split: \n",
      " medium    131\n",
      "hard       19\n",
      "easy        3\n",
      "Name: Levels, dtype: int64\n",
      "Dev split: \n",
      " medium    15\n",
      "hard       2\n",
      "easy       1\n",
      "Name: Levels, dtype: int64\n",
      "Test split:  \n",
      " medium    16\n",
      "hard       2\n",
      "easy       1\n",
      "Name: Levels, dtype: int64\n",
      "Fold:  1\n",
      "Fold:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/data/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/data/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/data/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/data/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/data/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_split(df):\n",
    "    X_train, X_test, _, _ = train_test_split(df[\"Query Pattern\"], df[\"Sql pattern\"], test_size = 0.1, stratify=df[['Levels']])\n",
    "\n",
    "    df.loc[X_train.index, \"split\"] = \"train\"\n",
    "    df.loc[X_test.index, \"split\"] = \"test\"\n",
    "\n",
    "    train_df = df[df['split'] == 'train']\n",
    "    test_df = df[df['split'] == 'test']\n",
    "    X_train, X_dev, _, _ = train_test_split(train_df[\"Query Pattern\"], train_df[\"Sql pattern\"], test_size = 0.1, stratify=train_df[['Levels']])\n",
    "\n",
    "    train_df.loc[X_train.index, \"split\"] = \"train\"\n",
    "    train_df.loc[X_dev.index, \"split\"] = \"dev\"\n",
    "\n",
    "    df = pd.concat([train_df, test_df])\n",
    "    return df\n",
    "\n",
    "for fold_id in range(3):\n",
    "    print(\"Fold: \", fold_id)\n",
    "    df = df1.copy()\n",
    "    df = get_split(df)\n",
    "    if fold_id==0:\n",
    "        print(\"Train split: \\n\", df[df['split'] == 'train']['Levels'].value_counts())\n",
    "        print(\"Dev split: \\n\", df[df['split'] == 'dev']['Levels'].value_counts())\n",
    "        print(\"Test split:  \\n\", df[df['split'] == 'test']['Levels'].value_counts())\n",
    "    df.to_csv(f'/data/unified_parser_text_to_sql/create_database_ours/booksql/folds/fold_{fold_id}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "958757f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split: \n",
      " medium    131\n",
      "hard       19\n",
      "easy        3\n",
      "Name: Levels, dtype: int64\n",
      "Dev split: \n",
      " medium    15\n",
      "hard       2\n",
      "easy       1\n",
      "Name: Levels, dtype: int64\n",
      "Test split:  \n",
      " medium    16\n",
      "hard       2\n",
      "easy       1\n",
      "Name: Levels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train split: \\n\", df[df['split'] == 'train']['Levels'].value_counts())\n",
    "print(\"Dev split: \\n\", df[df['split'] == 'dev']['Levels'].value_counts())\n",
    "print(\"Test split:  \\n\", df[df['split'] == 'test']['Levels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b3b2bb8-1164-4abe-9d0a-5cddbcb36ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = pd.read_csv(\"/data/unified_parser_text_to_sql/create_database_ours/booksql/customers.csv\")\n",
    "products = pd.read_csv(\"/data/unified_parser_text_to_sql/create_database_ours/booksql/products.csv\")\n",
    "vendors = pd.read_csv(\"/data/unified_parser_text_to_sql/create_database_ours/booksql/vendors.csv\")\n",
    "accounts = pd.read_csv(\"/data/unified_parser_text_to_sql/create_database_ours/booksql/chart_of_accounts.csv\")\n",
    "employee = pd.read_csv(\"/data/unified_parser_text_to_sql/create_database_ours/booksql/employees.csv\")\n",
    "date_ranges = pd.read_csv(\"/data/unified_parser_text_to_sql/create_database_ours/data/dataset details.xlsx - sample date ranges.csv\")\n",
    "date_ranges[\"sql\"] = date_ranges[\"sql\"].replace(r\"\\n\",\"\",regex=True)\n",
    "\n",
    "ignore_keys = [\"sample\", \"test\", \"quickbooks\", \"unknown\", \"my company\", \"customer\", \"cash\", \"sale\", \"deposit\", \".\", \"payroll\", \"anonymous\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e5dca28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customers shape:  (10000, 13)\n",
      "products shape:  (270, 4)\n",
      "vendors shape:  (10000, 8)\n",
      "accounts shape:  (2430, 5)\n",
      "employee shape:  (6000, 7)\n",
      "date_ranges shape:  (25, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"customers shape: \", customers.shape)\n",
    "print(\"products shape: \", products.shape)\n",
    "print(\"vendors shape: \", vendors.shape)\n",
    "print(\"accounts shape: \", accounts.shape)\n",
    "print(\"employee shape: \", employee.shape)\n",
    "print(\"date_ranges shape: \", date_ranges.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20e07ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample date ranges in questions</th>\n",
       "      <th>sql</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This fiscal year to date</td>\n",
       "      <td>BETWEEN date(current_date, '-3 months', 'start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This year to date</td>\n",
       "      <td>BETWEEN date(current_date, 'start of year') AN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This fiscal year</td>\n",
       "      <td>BETWEEN date(current_date, '-3 months', 'start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This year</td>\n",
       "      <td>BETWEEN date(current_date, 'start of year') AN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Last fiscal year</td>\n",
       "      <td>BETWEEN date(current_date, '-3 months', 'start...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample date ranges in questions  \\\n",
       "0        This fiscal year to date   \n",
       "1               This year to date   \n",
       "2                This fiscal year   \n",
       "3                       This year   \n",
       "4                Last fiscal year   \n",
       "\n",
       "                                                 sql  \n",
       "0  BETWEEN date(current_date, '-3 months', 'start...  \n",
       "1  BETWEEN date(current_date, 'start of year') AN...  \n",
       "2  BETWEEN date(current_date, '-3 months', 'start...  \n",
       "3  BETWEEN date(current_date, 'start of year') AN...  \n",
       "4  BETWEEN date(current_date, '-3 months', 'start...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_ranges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ea96dc7-cdba-4d6c-a81a-7ad0bd8b6bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_names(df, var):\n",
    "    flag = df[var].apply(lambda x: sum([y in x for y in ignore_keys]))\n",
    "    df = df[flag == 0].reset_index(drop = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42d8b258-ecdb-430e-87ac-cfffc803bc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokens(x):\n",
    "    return \" \".join([lemmatizer.lemmatize(y) for y in x.lower().split(\" \")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afe94ece-55c3-47ff-b32b-1fa6aed3253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variants(x):\n",
    "    variants = [x.lower()]\n",
    "    variants.append(stem_tokens(x))\n",
    "    if \"&\" in x:\n",
    "        x0 = x.split(\"&\")[0].strip().lower()\n",
    "        x1 = x.split(\"&\")[1].strip().lower()\n",
    "        variants.append(x0)\n",
    "        variants.append(stem_tokens(x0))\n",
    "        variants.append(x1)\n",
    "        variants.append(stem_tokens(x1))\n",
    "    if \"|\" in x:\n",
    "        x0 = x.split(\"|\")[0].strip().lower()\n",
    "        x1 = x.split(\"|\")[1].strip().lower()\n",
    "        variants.append(x0)\n",
    "        variants.append(stem_tokens(x0))\n",
    "        variants.append(x1)\n",
    "        variants.append(stem_tokens(x1))\n",
    "    variants = np.unique(variants)\n",
    "    return variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "996eb667-2ffd-41aa-9c0a-9d219b033bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_random_attribute(filter_by_attribute):\n",
    "    return random.sample(filter_by_attribute[random.sample(sorted(filter_by_attribute), 1)[0]].tolist(), 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c0f55d0-689c-4acc-9d4d-9fba6cf1ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = clean_names(customers, \"Customer name\")\n",
    "products = clean_names(products, \"Product_Service\")\n",
    "vendors = clean_names(vendors, \"Vendor name\")\n",
    "accounts = clean_names(accounts, \"Account name\")\n",
    "employee = clean_names(employee, \"Employee name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86ea4bfa-5933-4714-b461-85911bcf4672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "customers[\"Variants\"] = customers[\"Customer name\"].apply(lambda x: get_variants(x))\n",
    "products[\"Variants\"] = products[\"Product_Service\"].apply(lambda x: get_variants(x))\n",
    "vendors[\"Variants\"] = vendors[\"Vendor name\"].apply(lambda x: get_variants(x))\n",
    "accounts[\"Variants\"] = accounts[\"Account name\"].apply(lambda x: get_variants(x))\n",
    "employee[\"Variants\"] = employee[\"Employee name\"].apply(lambda x: get_variants(x))\n",
    "print(\"completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf3a3106-8b95-4ed9-8b84-2b75275175d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 50\n",
    "\n",
    "aggregation_entity = [\"total\", \"average\", \"mean\", \"max\", \"min\", \"first\", \"last\", \"highest\", \"lowest\"]\n",
    "\n",
    "intents = [\"sales\", \"expense\", \"invoice\", \"bill\", \"account payable\", \"account receivable\"]   #txn_type,\n",
    "\n",
    "date_filter_entity = date_ranges[\"sample date ranges in questions\"].tolist()\n",
    "date_sql_entity = dict(zip(date_ranges[\"sample date ranges in questions\"], date_ranges[\"sql\"]))\n",
    "\n",
    "filter_by_customer = customers.set_index(\"Customer name\").to_dict()[\"Variants\"]\n",
    "\n",
    "filter_by_product = products.set_index(\"Product_Service\").to_dict()[\"Variants\"]\n",
    "\n",
    "filter_by_vendor = vendors.set_index(\"Vendor name\").to_dict()[\"Variants\"]          #salesperson_name\n",
    "\n",
    "filter_by_account = accounts.set_index(\"Account name\").to_dict()[\"Variants\"]\n",
    "\n",
    "filter_by_employee = employee.set_index(\"Employee name\").to_dict()[\"Variants\"]\n",
    "\n",
    "group_by_entity = [\"account\", \"department\", \"vendor\", \"customer\", \"product\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e64ef64-c1fe-4df9-8dcf-2b6f4c2d3be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attributes_list = df[\"Query Pattern\"].apply(lambda x:  re.findall(r'\\[.*?\\]', str(x) ))\n",
    "# attributes_list = attributes_list.apply(lambda x: [y.replace(\"[\", \"\").replace(\"]\", \"\") for y in x])\n",
    "# attributes_list = [x for y in attributes_list for x in y]\n",
    "# pd.Series(attributes_list).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "394807f2-4199-4980-888d-0f005345e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_dict = {\n",
    "    \"date_filter\": date_filter_entity,\n",
    "    \"customer_name\": filter_by_customer,\n",
    "    \"vendor_name\": filter_by_vendor,\n",
    "    \"product_name\": filter_by_product,\n",
    "    \"aggregation_entity\": aggregation_entity,\n",
    "    \"account_name\": filter_by_account,\n",
    "    \"employee_name\": filter_by_employee,\n",
    "    \"groupby_entity\": group_by_entity,\n",
    "    #\n",
    "    # \"txn_type\": intents,\n",
    "    \"transaction_type\":intents,\n",
    "#     \"salesperson_name\": filter_by_vendor\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07347824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attributes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "621db0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aggregation(query):\n",
    "    if any(word in query for word in [\"average\", \"mean\"]):\n",
    "        return \"avg\"\n",
    "    elif any(word in query for word in [\"max\", \"last\", \"highest\"]):\n",
    "        return \"max\"\n",
    "    elif any(word in query for word in [\"min\", \"first\", \"lowest\"]):\n",
    "        return \"min\"\n",
    "    else:\n",
    "        return \"sum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f36c0db-3d66-4aac-af9b-7b9185c1f551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_random_attribute(attribute_dict):\n",
    "    # print(\"attribute_dict: \", attribute_dict)\n",
    "    return random.sample(attribute_dict[random.sample(sorted(attribute_dict), 1)[0]].tolist(), 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acd08eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(query_pattern,d_word,is_sql=0):\n",
    "    attributes = re.findall(r'\\[.*?\\]', str(query_pattern))\n",
    "    \n",
    "#     print(\"att: \",attributes)\n",
    "#     print(\"word: \",word)\n",
    "    \n",
    "#     assert len(attributes) == len(word)\n",
    "\n",
    "#     print(\"asdasdasdas      \",d_word)\n",
    "#     print(\"its attr : \" , attributes)\n",
    "#     print()\n",
    "#     return \"\"\n",
    "    \n",
    "    \n",
    "\n",
    "    for a in attributes:\n",
    "        \n",
    "        a_cleaned = re.sub(r\"[\\[\\]]\", \"\", a)\n",
    "\n",
    "        new_word = d_word[0][a_cleaned]\n",
    "\n",
    "        if is_sql == 1 and a_cleaned == \"aggregation_entity\" :\n",
    "            new_word = get_aggregation(new_word)\n",
    "        \n",
    "        elif is_sql == 1 and a_cleaned == \"date_filter\":                          #\"entity\" above dict\n",
    "            new_word = date_sql_entity[new_word]\n",
    "            a = '\"' + a + '\"'\n",
    "            \n",
    "            \n",
    "            # print(\"new word: \",new_word)\n",
    "            # print(\"new_word: \", d_word[0])\n",
    "            # # exit()\n",
    "            # new_word = new_word.values\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            query_pattern = query_pattern.replace(a, new_word)\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        \n",
    "#     for a,w in zip(attributes,word) :\n",
    "#         a_cleaned = re.sub(r\"[\\[\\]]\", \"\", a)\n",
    "#         query_pattern = query_pattern.replace(a, d_word[a])\n",
    "# #     print(\"$$$$\",query_pattern)\n",
    "    return query_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f018f93-cd68-48f6-8795-4ba2058110d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def replace_attributes(query_pattern):\n",
    "    temp = []\n",
    "    d = {}\n",
    "    attributes = re.findall(r'\\[.*?\\]', str(query_pattern))\n",
    "    for a in attributes:\n",
    "        a_cleaned = re.sub(r\"[\\[\\]]\", \"\", a)\n",
    "        \n",
    "        if type(attributes_dict[a_cleaned]) == list:\n",
    "            select_attribute = random.sample(attributes_dict[a_cleaned], 1)[0]\n",
    "        else:\n",
    "            select_attribute = choose_random_attribute(attributes_dict[a_cleaned])\n",
    "            # print(\"select_attribute: \", select_attribute)\n",
    "\n",
    "#         query_pattern = query_pattern.replace(a, select_attribute)\n",
    "#         temp.append(select_attribute)\n",
    "        \n",
    "        d[a_cleaned]  =  select_attribute\n",
    "    \n",
    "    temp.append(d)\n",
    "    # print(\"temp: \", temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4331fb3b-c00e-4375-852f-f19ce9c6df89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34d4c56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.iloc[0][\"Query Pattern\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46eff4c5-9623-40dd-9236-35d7602467bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_questions(n, df):\n",
    "    df_sample = df[~df[\"Query Pattern\"].apply(lambda x: \"salesperson_name\" in x)].reset_index(drop=True)\n",
    "    \n",
    "    df_simulated = df_sample.loc[random.choices(range(len(df_sample)), k=n)].reset_index(drop=True)\n",
    "    \n",
    "#     df_simulated[\"Query\"] = df_simulated[\"Query Pattern\"].apply(lambda x: replace_attributes(x))\n",
    "    \n",
    "#     df_simulated[\"Sql pattern new\"] = df_simulated[\"Sql pattern\"].apply(lambda x: replace_attributes(str(x)))\n",
    "    # df_simulated.loc[df_simulated[\"Aggregation\"].isna(), \"Aggregation\"] = df_simulated[df_simulated[\"Aggregation\"].isna()][\"Query\"].apply(lambda x: get_aggregation(x))\n",
    "\n",
    "    ls1 = df_simulated[\"Query Pattern\"].apply(lambda x: replace_attributes(x)).to_list()\n",
    "    # print(\"ls1: \", ls1)\n",
    "    df_simulated[\"Query\"] = np.nan\n",
    "    df_simulated[\"Sql pattern new\"] = np.nan\n",
    "    \n",
    "    for i in range(len(ls1)):\n",
    "        df_simulated.loc[[i],[\"Query\"] ] = f1(df_simulated.iloc[i][\"Query Pattern\"],ls1[i])\n",
    "        df_simulated.loc[[i],[\"Sql pattern new\"] ] = f1(df_simulated.iloc[i][\"Sql pattern\"],ls1[i],is_sql=1)\n",
    "    \n",
    "    # df_simulated[\"Sql pattern new\"\"].apply(lambda x : )\n",
    "    \n",
    "    return df_simulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f65c177",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold id:  0\n",
      "Fold id:  1\n",
      "Fold id:  2\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "for fold_id in range(3):\n",
    "    print(\"Fold id: \", fold_id)\n",
    "    df = pd.read_csv(f\"/data/unified_parser_text_to_sql/create_database_ours/booksql/folds/fold_{fold_id}.csv\")\n",
    "    df_simulated = simulate_questions(13000, df)\n",
    "    df_simulated[\"Sql pattern\"] = df_simulated[\"Sql pattern\"].replace(r\"\\n\",\"\",regex=True)\n",
    "    df_simulated[\"Sql pattern new\"] = df_simulated[\"Sql pattern new\"].replace(r\"\\n\",\"\",regex=True)\n",
    "    final_df = df_simulated[['Query','Sql pattern new', 'Levels', 'split']]\n",
    "    final_df.to_csv(f\"/data/unified_parser_text_to_sql/create_database_ours/booksql/sql_pairs/sql_pairs_fold_id{fold_id}.csv\")\n",
    "    final_df.head()\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f482a490",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
