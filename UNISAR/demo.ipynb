{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import json\n",
    "import sqlite3\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    string = str(string)\n",
    "    string = string.replace(\"\\'\", \"\\\"\")  # ensures all string values wrapped by \"\" problem??\n",
    "    quote_idxs = [idx for idx, char in enumerate(string) if char == '\"']\n",
    "    assert len(quote_idxs) % 2 == 0, \"Unexpected quote\"\n",
    "\n",
    "    # keep string value as token\n",
    "    vals = {}\n",
    "    for i in range(len(quote_idxs)-1, -1, -2):\n",
    "        qidx1 = quote_idxs[i-1]\n",
    "        qidx2 = quote_idxs[i]\n",
    "        val = string[qidx1: qidx2+1]\n",
    "        key = \"__val_{}_{}__\".format(qidx1, qidx2)\n",
    "        string = string[:qidx1] + key + string[qidx2+1:]\n",
    "        vals[key] = val\n",
    "\n",
    "    toks = [word.lower() for word in word_tokenize(string)]\n",
    "    # replace with string value token\n",
    "    for i in range(len(toks)):\n",
    "        if toks[i] in vals:\n",
    "            toks[i] = vals[toks[i]]\n",
    "\n",
    "    # find if there exists !=, >=, <=\n",
    "    eq_idxs = [idx for idx, tok in enumerate(toks) if tok == \"=\"]\n",
    "    eq_idxs.reverse()\n",
    "    prefix = ('!', '>', '<')\n",
    "    for eq_idx in eq_idxs:\n",
    "        pre_tok = toks[eq_idx-1]\n",
    "        if pre_tok in prefix:\n",
    "            toks = toks[:eq_idx-1] + [pre_tok + \"=\"] + toks[eq_idx+1: ]\n",
    "\n",
    "    return toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent = \"select sum(credit) as T1 from table;\"\n",
    "sent = 'select product_service from ( select product_service, count(distinct strftime(\"%m\", transaction_date)) as n_months from master_txn_table where customers = \"[customer_name]\" and strftime(\"%m\", transaction_date) >= strftime(\"%m\", current_date) - 6 group by product_service ) where n_months >= 6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGG_OPS = ('none', 'max', 'min', 'count', 'sum', 'avg','month','year','week','date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scan_alias(toks):\n",
    "    \"\"\"Scan the index of 'as' and build the map for all alias\"\"\"\n",
    "\n",
    "    as_idxs = [idx for idx, tok in enumerate(toks) if tok == 'as']\n",
    "    \n",
    "    alias = {}\n",
    "    for idx in as_idxs:\n",
    "        temp = toks[idx-1]\n",
    "\n",
    "        for i in range(idx,-1,-1):\n",
    "            if toks[i] in AGG_OPS:\n",
    "                temp = \" \".join(toks[i:idx-1 +1])\n",
    "                break\n",
    "        \n",
    "        alias[toks[idx+1]] = temp\n",
    "    return alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_months': 'count ( distinct strftime ( \"%m\" , transaction_date ) )'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan_alias(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.index(\"select\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
